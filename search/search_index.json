{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction A simple library to quantize your ML models.","title":"Introduction"},{"location":"#introduction","text":"A simple library to quantize your ML models.","title":"Introduction"},{"location":"CONTRIBUTING/","text":"# Contributing to approx We welcome all contributors! Please visit our issues page to have a look around. Dev setup We hope that you will find approx extremely easy to set up. After cloning our repository, you can simply run Bash # to install project dependencies poetry install # to install pre-commit for linting pre-commit install and start working on the libs immediately!","title":"Contributing to `approx`"},{"location":"CONTRIBUTING/#dev-setup","text":"We hope that you will find approx extremely easy to set up. After cloning our repository, you can simply run Bash # to install project dependencies poetry install # to install pre-commit for linting pre-commit install and start working on the libs immediately!","title":"Dev setup"},{"location":"api_reference/","text":"API reference Main API auto_quantize ( model , pretrained = True ) Turns a normal model into a quantized model, using an appropriate backend Parameters: Name Type Description Default model Any The model to quantize. required pretrained bool Whether this model is pretrained True Source code in approx/core/api.py Python 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def auto_quantize ( model : Any , pretrained : bool = True ) -> Any : \"\"\"Turns a normal model into a quantized model, using an appropriate backend Args: model: The model to quantize. pretrained: Whether this model is pretrained \"\"\" if _vars . _APPROX_BACKEND is None : raise ValueError ( \"No backend has been set. \" \"Please call `approx.auto_set_backend()`.\" ) qmodel = _vars . _APPROX_BACKEND . auto_quantize ( model , pretrained ) return qmodel auto_set_backend () Automatically sets an appropriate backend for approx to use. Returns: Type Description None None. Source code in approx/core/api.py Python 49 50 51 52 53 54 55 56 def auto_set_backend () -> None : \"\"\"Automatically sets an appropriate backend for `approx` to use. Returns: None. \"\"\" _vars . _APPROX_BACKEND = auto_select_backend () compare ( model , quantized_model , test_loader , * , eval_loop ) Compares your normal model with your quantized model Parameters: Name Type Description Default model Any Your normal model required quantized_model Any Your quantized model required test_loader Any The \"dataloader\" to be used for testing. required eval_loop EvalLoop Your evaluation loop that operates on your model and it's data, and returns a dictionary which maps each metric to its history required Returns: Type Description CompareResult Useful statistical information Source code in approx/core/api.py Python 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def compare ( model : Any , quantized_model : Any , test_loader : Any , * , eval_loop : EvalLoop ) -> CompareResult : \"\"\" Compares your normal model with your quantized model Args: model: Your normal model quantized_model: Your quantized model test_loader: The \"dataloader\" to be used for testing. eval_loop: Your evaluation loop that operates on your model and it's data, and returns a dictionary which maps each metric to its history Returns: Useful statistical information \"\"\" runner = _CompareRunner ([ model , quantized_model ], test_loader , eval_loop ) return runner . run () Types EvalLoop A function which accepts your model and the data, and returns a dictionary mapping metrics to their histories. For example Python def eval_loop ( model , data ): return { \"loss\" : [ 1.0 , 2.0 ], \"accuracy\" : [ 3.0 , 4.0 ], } Bases: Protocol Source code in approx/core/compare.py Python 9 10 11 class EvalLoop ( Protocol ): def __call__ ( self , model : Any , test_dl : Any ) -> Dict [ str , List [ float ]]: ...","title":"API reference"},{"location":"api_reference/#api-reference","text":"","title":"API reference"},{"location":"api_reference/#main-api","text":"","title":"Main API"},{"location":"api_reference/#approx.auto_quantize","text":"Turns a normal model into a quantized model, using an appropriate backend Parameters: Name Type Description Default model Any The model to quantize. required pretrained bool Whether this model is pretrained True Source code in approx/core/api.py Python 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def auto_quantize ( model : Any , pretrained : bool = True ) -> Any : \"\"\"Turns a normal model into a quantized model, using an appropriate backend Args: model: The model to quantize. pretrained: Whether this model is pretrained \"\"\" if _vars . _APPROX_BACKEND is None : raise ValueError ( \"No backend has been set. \" \"Please call `approx.auto_set_backend()`.\" ) qmodel = _vars . _APPROX_BACKEND . auto_quantize ( model , pretrained ) return qmodel","title":"auto_quantize()"},{"location":"api_reference/#approx.auto_set_backend","text":"Automatically sets an appropriate backend for approx to use. Returns: Type Description None None. Source code in approx/core/api.py Python 49 50 51 52 53 54 55 56 def auto_set_backend () -> None : \"\"\"Automatically sets an appropriate backend for `approx` to use. Returns: None. \"\"\" _vars . _APPROX_BACKEND = auto_select_backend ()","title":"auto_set_backend()"},{"location":"api_reference/#approx.compare","text":"Compares your normal model with your quantized model Parameters: Name Type Description Default model Any Your normal model required quantized_model Any Your quantized model required test_loader Any The \"dataloader\" to be used for testing. required eval_loop EvalLoop Your evaluation loop that operates on your model and it's data, and returns a dictionary which maps each metric to its history required Returns: Type Description CompareResult Useful statistical information Source code in approx/core/api.py Python 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def compare ( model : Any , quantized_model : Any , test_loader : Any , * , eval_loop : EvalLoop ) -> CompareResult : \"\"\" Compares your normal model with your quantized model Args: model: Your normal model quantized_model: Your quantized model test_loader: The \"dataloader\" to be used for testing. eval_loop: Your evaluation loop that operates on your model and it's data, and returns a dictionary which maps each metric to its history Returns: Useful statistical information \"\"\" runner = _CompareRunner ([ model , quantized_model ], test_loader , eval_loop ) return runner . run ()","title":"compare()"},{"location":"api_reference/#types","text":"","title":"Types"},{"location":"api_reference/#evalloop","text":"A function which accepts your model and the data, and returns a dictionary mapping metrics to their histories. For example Python def eval_loop ( model , data ): return { \"loss\" : [ 1.0 , 2.0 ], \"accuracy\" : [ 3.0 , 4.0 ], } Bases: Protocol Source code in approx/core/compare.py Python 9 10 11 class EvalLoop ( Protocol ): def __call__ ( self , model : Any , test_dl : Any ) -> Dict [ str , List [ float ]]: ...","title":"EvalLoop"}]}